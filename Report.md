# Final Project Report

**Project URL**: http://b52e04a3fab4.ngrok.io

<!-- Short (~250 words) abstract of the concrete data science problem and how the solutions addresses the problem. -->

## Introduction

Music is very often compared: How does an artists new album compare to their previous? Who's better, Tupac or Biggie?  Lyrics make up such an important part of music, but there does not exist a tool specifically for comparing the lyrics from two songs. Text comparison is a very difficult task since it requires a strong grasp on a language.  In this project, we introduce a tool for comparing lyrics from two songs.  This tool is designed to expand users' abilities to contrast text by providing interactive tools for comparing words, lines of words, and the positivity of lyrics.


## Related Work

There are many sources that provide lyrics for one song at a time, such as [Genius](http://genius.com), [AZLyrics](http://azlyrics.com), or [Lyrics.com](http://lyrics.com).  Genius provides a mechanism where users can annotate lyrics to explain their meaning.  None of these services provide a way to directly compare lyrics from two songs.

There are examples of articles where an author uses Natural Language Processing to compare the lyrics of [multiple songs by the same artist](https://towardsdatascience.com/drake-using-natural-language-processing-to-understand-his-lyrics-49e54ace3662) or [songs in multiple genres](https://towardsdatascience.com/using-sentence-embeddings-to-explore-the-similarities-and-differences-in-song-lyrics-1820ac713f00).  In these works, an author explores the lyrics to confirm some hypothesis about them such as [whether rappers have positive messages](https://github.com/Hugo-Nattagh/2017-Hip-Hop) or [if Country music "drinks" more than other generes](https://towardsdatascience.com/does-country-music-drink-more-than-other-genres-a21db901940b).  The analysis in these works is tailored to answering the hypothesis.  As far as we've been able to determine through our research, our tool is the first lyric analysis tool that allows a user to explore their own hypotheses about the differences in the lyrics.


## Methods

**Lyrics** Lyrics are collected using the [Genius API](https://docs.genius.com/).  The lyrics are displayed as text using custom html/CSS which can connect with the D3JS plots.

**Word & Line Similarities**  Each word and whole line of words in the lyrics is fed through the [Bidirectional Encoder Representations from Transformer (BERT)](https://arxiv.org/abs/1810.04805) model to extract text embeddings.  The last four hidden states of the BERT model are concatenated to form the embedding.  Text embeddings are vectors with 3072 values representing a word or text.  The BERT model was trained such that words or text that are very similar to each other have very similar embeddings in terms of Euclidean distance between the embedding vectors.

The text embeddings are high dimensional so they cannot easily be understood by humans.  We reduce this dimensionality using [t-Distributed Stochastic Neighbor Embedding](https://www.jmlr.org/papers/v9/vandermaaten08a.html) (t-SNE) to just two dimensions.  t-SNE reduces dimensionality while preserving relativity between the points, so words that are similar should still have similar embeddings in terms of the Euclidean distance.

The two valued vectors for words or lines are plotted onto a scatter plot using D3JS.  Hovering over the points will show you which word or line in the lyrics the point represents.  Points can be selected through clicking or brushing which will also highlight the points in the lyric text.  The words or lines can also be selected in the lyrics text by clicking which will highlight the word or line in the scatter plot.

**Positivity**  We use the [HuggingFace](huggingface.co) transformers library for sentiment analysis on the lyrics.  Each word and line in the lyrics is fed through the pre-trained DistilBERT model which produces a classification of the word or line as positive or negative along with a confidence score.  In order to compare how each song uses positivity, we categorize each word as how the individual word is categorized with its surrounding line's categorization.  For instance, a positive word in a positive line is categorized as pos_word_pos_line, a negative word in a postive line is pos_word_neg_line and so on.  A bar plot is created using D3JS showing the percentages of these cases in each song.  Clicking on a bar will highlight the words that fall under that cross-categorization.  The classification of each line of lyrics is also shown to the left of each line where green indicates positive and red indicates negative lines of lyrics.

**Song Previews**  A 30-second preview of each song is collected using the [Spotify API](https://developer.spotify.com/documentation/web-api/).

## Results
### Our application has three visualizations:
1. **Word Similarities** presents a 2-D scatter plot of the t-SNE embeddings on a word basis. The words from the two songs are combined into one data set for processing, but are presented on the scatter plot in different colors, with the words from the left song as green points and the words from the right song as purple points. The intent of this visualization is to display the similarity of the vocabularies of the songs in a meaningful way. Among possible insights, this visualization reveals if the two songs use many of the same exact words or if they use different words that have very similar meanings. Words that are closer to each other on the plot are more similar. In testing we found that words with the same part of speech or word type (e.g. pronouns, contractions) were often close together and words with shared thematic elements (e.g. life, death) were often close together. The interactions with this plot include hovering over a point to see a tooltip of the word associated with the point, clicking a point to highlight in orange the associated word in the two songs, brushing over a set of points in order to highlight in orange all of their associated words in the two songs, and clicking on words in either of the songs in order to highlight in blue their associated points in the scatter plot.
2. **Line Similarities** presents a 2-D scatter plot of the t-SNE embeddings on a line basis. The lines from the two songs are combined into one data set for processing, but are presented on the scatter plot in different colors, with the lines from the left song as green points and the lines from the right song as purple points. The intent of this visualization is to display the similarity of the lyrics of the two songs. Among possible insights, this visualization reveals if there are variations of the same phrase being used within or between songs and if the meaning of the lines are similar enough that they could be mistaken (by this model) as being from one song. In testing we found examples where the unexpected occurred: two songs with very different origins whose plotted points overlapped and two songs where one sampled the other and their points were clearly separate. The interactions with this plot include hovering over a point to see a tooltip of the line associated with the point, clicking a point to highlight in orange the associated line in the two songs, brushing over a set of points in order to highlight in orange all of their associated lines in the two songs, and clicking on lines in either of the songs in order to highlight in blue their associated points in the scatter plot.
3. **Positivity** presents the positivity of the songs in two ways. It shows a heat map next to the lyrics of each song with a red square indicating that a line is negative and a green square indicating that a line is positive. It also shows a bar plot of the positivity of the words vs. the positivity of lines plotting the percentages of four categories of words in each song: positive words in positive lines (pos_word_pos_line), negative words in negative lines (neg_word_neg_line), positive words in negative lines (pos_word_neg_line), and negative words in positive lines (neg_word_pos_line). The left song's bars are green and the right song/s bars are purple. The positivity of the words and lines is calculated by inputting each word and each line into the HuggingFace Library's sentiment-analysis classifier. Though the value returned from the classifier includes a label (POSITIVE, NEGATIVE) and a confidence measure on a scale of 0.0 to 1.0, we found in testing that the classifier was usually very confident (0.9-1.0). For this reason, we decided to present the positivity as a discrete quantity to the user. In our first prototype we had a scatter of word positivity vs. line positivity and found it to interesting to see when the sentiment of a line didn't match with the sentiment of a word. We wanted to keep the opportunity for this insight, and decided to display the combinations in a bar plot, normalized to percentages to account for the situation where one of the songs has many more words than the other. The interactions with this plot include clicking on one of the song's bars in order to highlight all of the words that match its label in that song.

### Two case studies:
1. Using our application to compare *Step To My Girl* by Souls of Mischief and *Step* by Vampire Weekend, Danny Brown illustrated the usefulness of the word similarity and line similarity visualizations. In both, the points are highly overlapping. Though we saw overlapping in the word similarity plot for other song pairs, this was one of the few pairs for which there was also overlapping in the line similarity plot. What's so interesting about this pairing is that the two songs aren't covers of the same song - they have no shared origin story - and yet they are very similar. For instance, in *Step To My Girl* there is a line "Catch crazy glares when I'm with female company" and in *Step* there is a line "Every time I'm with her, dudes always wanna stare." In the line similarity plot the points for these two lines are very close together. These lines mean the same thing, but are said in two different ways. In the word similarity plots there are many pairs of points close together. For example, the words "make" and "sees" from *Step To My Girl* and "made" and "seen" from *Step* are all near each other in the plot. These points illustrate that *Step To My Girl* is speaking in the present tense whereas *Step* is speaking in the past tense. Interacting with these similarity plots allowed us to interpret what is shared among the songs - by words and by lines - and to make our own judgements about where the similarities end and the meanings of the songs are different.
2. Using our application to compare *Just the Two of Us* by Will Smith and *Just the Two of Us* by Grover Washington Jr. illustrated the usefulness of the positivity visualization. Will Smith's song samples Grover Washington Jr.'s for the chorus, but where Grover Washington Jr.'s depicts a romantic relationship, Will Smith's depicts a father-son relationship. In examining the positivity bar plot, we saw that both of the songs are overwhelming positive. About 65% of Will Smith's song are positive words in positive lines and about 80% of Grover Washington Jr.'s song are positive words in positive lines. The heat map shows that the negative lines are distributed throughout each song rather than being grouped together. By selecting the negative words in negative lines, we saw that in both cases there were one or two negative words in a negative line that influenced the line's classification. For instance, in Will Smith's song, words "death," "let," and "harm" are classified as negative in the negatively-classified line "I knew I'd meet death before I'd let you meet harm." Even though this line speaks about possible negative events, it could be interpreted as a positive sentiment because it demonstrates the speaker's value for their son's safety. Interacting with the positivity visualizations allowed us to get a broader understanding of how the words and lines could be classified individually, and allowed us to make our own judgements of how the positivity of the songs change throughout their lyrics and of how positive the songs are as a whole.

## Discussion
Our application allows users to consider songs from a different perspective than they might when they are listening. In an informal test, the user said that they found the positivity visualization to be interesting because they don't usually think about positivity when considering the songs that they listen to. Usually they think about the music's style: the beat, key, etc. They thought the heat map was helpful for noticing patterns in positiveness through the arc of the song. The feedback for improvement from the user was that overlapping points could be better distinguished in some way. They found it confusing that the green and purple overlapping produced a darker grey-purple. In addition, their initial reaction to the line similarity was that it didn't make as much sense to them because their assumption was that there wouldn't be that many similar lines between different songs.

## Future Work

For future work on this project, we would like to explore additional dimensions of comparison between lyrics. Words could be analyzed for their parts of speech and compared between songs to see how each artist uses language. Additional sentiments beyond positivity could be extracted from the lyrics for comparison such as love, happiness, anger, or sadness.

Our tool provides a nice playground for users to explore the differences or similarities in two songs, but in future work we could make this more directed by automatically pulling out interesting information.  For instance, the N most similar pairs of lyrics could be displayed for convenience.

We would also like to extend this tool to work at a larger granularity than just songs.  In future work, users could compare lyrics from whole albums or compare artists' discographies.
